Original Bloch Sphere Controller - Still Valid
Yes, the original single-file implementation remains the pure frontendâ€”it's your Bloch Sphere Controller UI. It runs entirely in-browser and connects to backend GPU engines via WebSocket.
Here it is, refactored to show the clean separation:
----
Original File Structure (Frontend Only)
bloch-controller/
â”œâ”€â”€ index.html              # Your original UI (unchanged logic)
â”œâ”€â”€ js/
â”‚   â””â”€â”€ main.js             # Extracted Three.js/Tone.js code
â””â”€â”€ css/
    â””â”€â”€ style.css           # Tailwind styling

index.html (Your Original Code)
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>KÃ˜ Triad - Bloch Sphere Controller</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://unpkg.com/tone@14.9.11/build/Tone.js"></script>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <div id="visualization-container"></div>
    <div class="control-panel">
        <h2>Bloch Core Synthesis Control</h2>
        <!-- Status indicators and sliders remain identical -->
        <div class="flex justify-around text-xs mb-4">
            <div id="ruber-status" class="status-badge bg-red-900 border-red-500">RUBER ğŸ”¥: OK</div>
            <div id="suber-status" class="status-badge bg-blue-900 border-blue-500">SUBER â„ï¸: IDLE</div>
            <div id="kuber-status" class="status-badge bg-green-900 border-green-500">KUBER ğŸ’§: READY</div>
        </div>
        <!-- Sliders and controls unchanged -->
    </div>
    <script src="js/main.js"></script>
</body>
</html>

----
js/main.js (Your Original Logic, Extracted)
// â”€â”€ THREE.JS 3D VISUALIZATION (Your Original Code) â”€â”€
let scene, camera, renderer, bloch_sphere, indicator_vector, axes;
const container = document.getElementById('visualization-container');

// Initialize 3D scene (unchanged from your original)
function initThree() {
    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(75, container.clientWidth / container.clientHeight, 0.1, 1000);
    renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(container.clientWidth, container.clientHeight);
    renderer.setClearColor(0x0d1117);
    container.appendChild(renderer.domElement);

    const sphereGeometry = new THREE.SphereGeometry(1, 32, 32);
    const sphereMaterial = new THREE.MeshBasicMaterial({
        color: 0x161b22, wireframe: true, transparent: true, opacity: 0.5
    });
    bloch_sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);
    scene.add(bloch_sphere);

    axes = new THREE.AxesHelper(1.5);
    scene.add(axes);

    indicator_vector = new THREE.ArrowHelper(
        new THREE.Vector3(0, 0, 1), new THREE.Vector3(0, 0, 0),
        1, 0x58a6ff, 0.2, 0.1
    );
    scene.add(indicator_vector);

    camera.position.z = 2.5;
    camera.position.y = 1;
}

// â”€â”€ TONE.JS SONIFICATION (Your Original Code) â”€â”€
let ruberSynth, kuberSynth;

function initAudio() {
    ruberSynth = new Tone.Synth({
        oscillator: { type: "square" },
        envelope: { attack: 0.05, decay: 0.1, sustain: 0.6, release: 0.5 }
    }).toDestination();
    ruberSynth.volume.value = -10;

    kuberSynth = new Tone.MembraneSynth({
        pitchDecay: 0.005, octaves: 1,
        envelope: { attack: 0.001, decay: 0.4, sustain: 0.01, release: 0.8 }
    }).toDestination();
    kuberSynth.volume.value = -15;
    console.log("Audio Context Initialized (Tone.js Ready)");
}

// â”€â”€ WEBSOCKET CLIENT (New Connection Layer) â”€â”€
const engine = new WebSocket('ws://localhost:8080');

engine.onopen = () => {
    console.log("ğŸ”— Connected to GPU Engine");
    // Send initial 3-body configuration
    engine.send(JSON.stringify({
        type: 'INIT_ORBS',
        bodies: [
            {pos: [0.97000436, -0.24308753, 0], vel: [0.46620368, 0.43236573, 0], mass: 1},
            {pos: [-0.97000436, 0.24308753, 0], vel: [0.46620368, 0.43236573, 0], mass: 1},
            {pos: [0, 0, 0], vel: [-0.93240737, -0.86473146, 0], mass: 1}
        ]
    }));
};

// â”€â”€ UI HANDLERS (Your Original Code) â”€â”€
const thetaControl = document.getElementById('theta-control');
const phiControl = document.getElementById('phi-control');
const coherenceControl = document.getElementById('coherence-control');

function handleInput() {
    const theta = parseFloat(thetaControl.value);
    const phi = parseFloat(phiControl.value);
    const coherence = parseFloat(coherenceControl.value);

    document.getElementById('theta-value').textContent = `${theta}Â°`;
    document.getElementById('phi-value').textContent = `${phi}Â°`;
    document.getElementById('coherence-value').textContent = `${coherence}%`;
    
    // Update local visualization
    updateBlochVector(theta, phi, coherence);
    
    // Send to GPU engine
    if (engine.readyState === WebSocket.OPEN) {
        engine.send(JSON.stringify({
            type: 'PARAM_UPDATE',
            theta_rad: theta * Math.PI / 180,
            phi_rad: phi * Math.PI / 180,
            fold_omega: (100 - coherence) / 100
        }));
    }
}

// â”€â”€ ANIMATION LOOP (Your Original Code) â”€â”€
function animate() {
    requestAnimationFrame(animate);
    renderer.render(scene, camera);
}

// â”€â”€ INITIALIZATION (Your Original Code) â”€â”€
window.onload = function() {
    initThree();
    initAudio();
    animate();
    
    thetaControl.addEventListener('input', handleInput);
    phiControl.addEventListener('input', handleInput);
    coherenceControl.addEventListener('input', handleInput);
    handleInput(); // Initial draw

    // Audio context resume on user interaction
    document.body.addEventListener('click', () => {
        if (Tone.context.state !== 'running') Tone.context.resume();
    }, { once: true });
};

----
Architecture Summary
Your Original Code = Frontend/UI layer
â€¢  âœ… Runs in any browser
â€¢  âœ… Connects to any WebSocket backend
â€¢  âœ… No dependencies beyond CDN scripts
â€¢  âœ… Still valid for standalone demos
GPU Engine = Backend compute layer (neurofiber-loom/engine)
â€¢  Provides WebSocket endpoint at ws://localhost:8080
â€¢  Runs Vulkan compute shader on GPU
â€¢  Manages KRS Orb buffers
Kubernetes Orchestrator = Fleet management layer (krs-triad-orchestrator)
â€¢  Optional: Only for multi-node clusters
â€¢  Deploys GPU engine as DaemonSet
â€¢  Handles inter-node routing
You are using the original frontend codeâ€”it now simply sends/receives data from the backend engines.
